{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from io import BytesIO\n",
    "import codecs\n",
    "import math\n",
    "import nltk\n",
    "from nltk.grammar import is_nonterminal\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def readfile(file):\n",
    " fp = codecs.open(file,\"rU\", encoding=\"utf8\",errors='ignore')\n",
    " text = fp.read()\n",
    " return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lower_case(tokens):\n",
    "    normal_tokens = [w.lower() for w in tokens]     #normalised tokens\n",
    "    return normal_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infants type Class\n",
      "N42b489ddddb841858be474abdb6d2296 maxQualifiedCardinality 7\n",
      "Volume subClassOf N42b489ddddb841858be474abdb6d2296\n",
      "N42b489ddddb841858be474abdb6d2296 onClass Volume\n",
      "Route type Class\n",
      "Unit type Class\n",
      "mg type NamedIndividual\n",
      "N4d6c0251ff584542842bc5f512c2530f someValuesFrom Unit\n",
      "hasUnit type ObjectProperty\n",
      "N0bc10627cedc491bba9e075b854d51bf minQualifiedCardinality 32\n",
      "mcl/kg type NamedIndividual\n",
      "weeks type NamedIndividual\n",
      "N4d6c0251ff584542842bc5f512c2530f type Restriction\n",
      "mcl/kg type Unit\n",
      "N0bc10627cedc491bba9e075b854d51bf onClass Age\n",
      "Intermittent type Route\n",
      "weeks type Unit\n",
      "Infants subClassOf N4d6c0251ff584542842bc5f512c2530f\n",
      "hasPostmenstrualAge domain Infants\n",
      "Suppositories subClassOf N57ff83ee21fe4cbbb85ac488bbbc677f\n",
      "kg type Unit\n",
      "Intermittent type NamedIndividual\n",
      "kg type NamedIndividual\n",
      "https://www.childhealthimprints.com/cardinalities/ type Ontology\n",
      "hasAdministrativeVolume type ObjectProperty\n",
      "hasPostmenstrualAge type ObjectProperty\n",
      "minutes hasUnit weeks\n",
      "Infants equivalentClass Neonate\n",
      "Intravenous type NamedIndividual\n",
      "N57ff83ee21fe4cbbb85ac488bbbc677f someValuesFrom Unit\n",
      "mg type Unit\n",
      "minutes type Unit\n",
      "mg/kg type Unit\n",
      "Volume type Class\n",
      "N57ff83ee21fe4cbbb85ac488bbbc677f onProperty hasDose\n",
      "hasPostmenstrualAge range Age\n",
      "Infants subClassOf N0bc10627cedc491bba9e075b854d51bf\n",
      "N42b489ddddb841858be474abdb6d2296 type Restriction\n",
      "hours type Unit\n",
      "Age type Class\n",
      "Suppositories type Class\n",
      "N0bc10627cedc491bba9e075b854d51bf onProperty hasPostmenstrualAge\n",
      "N4d6c0251ff584542842bc5f512c2530f onProperty hasDose\n",
      "hours type NamedIndividual\n",
      "N42b489ddddb841858be474abdb6d2296 onProperty hasAdministrativeVolume\n",
      "Intravenous type Route\n",
      "Neonate type Class\n",
      "N0bc10627cedc491bba9e075b854d51bf type Restriction\n",
      "minutes type NamedIndividual\n",
      "mg/kg type NamedIndividual\n",
      "hasDose type ObjectProperty\n",
      "N57ff83ee21fe4cbbb85ac488bbbc677f type Restriction\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"          \\nfor g in on:\\n search_keywords=''.join(on)\\n print(search_keywords)\\nfor g in of:\\n search_keywords1=''.join(of)\\n print(search_keywords1)\\n\""
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdflib import Graph\n",
    "from rdflib import URIRef\n",
    "g = Graph()\n",
    "g.parse(\"D:\\\\model\\\\cardinal.owl\")    # import owl file\n",
    "aClass = URIRef(\"https://www.childhealthimprints.com/cardinalities/\")\n",
    "\n",
    "rdfType = URIRef(\"http://www.w3.org/1999/02/22-rdf-syntax-ns#type\")\n",
    "#rdfType = URIRef(\"https://www.childhealthimprints.com/cardinalities/#hasPostmenstrualAge\")\n",
    "\n",
    "from rdflib.namespace import RDFS\n",
    "\n",
    "\n",
    "#for triple in g.triples((None,rdfType,None)):\n",
    " #   print(triple)\n",
    "    \n",
    "\n",
    "subject=[]\n",
    "predicate=[]\n",
    "object=[]\n",
    "\n",
    "for s,o,p in g.triples((None,None,None)):\n",
    "    print(s.rsplit('#')[-1],o.rsplit('#')[-1],p.rsplit('#')[-1])\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for subj, obj in g.subject_objects(predicate=rdfType):\n",
    "    on=subj.rsplit('#')[-1]\n",
    "    of=obj.rsplit('#')[-1]\n",
    "#    print(on)\n",
    " #   print(of)\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"          \n",
    "for g in on:\n",
    " search_keywords=''.join(on)\n",
    " print(search_keywords)\n",
    "for g in of:\n",
    " search_keywords1=''.join(of)\n",
    " print(search_keywords1)\n",
    "\"\"\"   \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10 mg/kg/dose IV every 6 hours as needed or around-the-clock', 'May consider a 20 mg/kg loading dose', '7.5 mg/kg/dose IV every 6 hours (maximum 30 mg/kg/24 hours) as needed or around the clock for pain or fever', '20 to 25 mg/kg orally', 'then 12 to 15 mg/kg/dose every 12 hours as needed or around-the-clock', 'then 12 to 15 mg/kg/dose every 6 hours as needed or around-the-clock', '30 mg/kg rectally', 'then 12 to 18 mg/kg/dose every 12 hours as needed or around-the-clock', 'A 20 mg/kg loading dose achieved a Cmax of 15 to 25 mg/L in 19 neonates (27 to 42 weeks gestational age) included in the PARANEO study', 'An effect compartment concentration of 10 mg/L was associated with a pain score reduction of 3.4 units', 'A mean plasma concentration of 11 mg/L after acetaminophen IV 10 mg/kg every 6 hours (with or without a 20 mg/kg loading dose) was predicted from a pharmacokinetic analysis of 158 neonates (28 to 44 weeks gestation)', 'No significant increases in liver enzymes were observed after a median duration of 60 hours (6 to 480 hours) and a median of 9 (2 to 80) doses of IV acetaminophen (20 mg/kg loading dose)', '10 mg/kg (every 6 hours for more than 36 weeks postmenstrual age (PMA), every 8 hours for 31 to 36 weeks PMA, and every 12 hours for less than 31 weeks postmenstrual age) in 189 infants (1 day to 182 days of age; 30 to 55 weeks PMA), in a retrospective analysis', 'Available orally in various liquid formulations containing 32, 80, and 100 mg/mL', 'Suppositories contain 80,120, 325, and 650 mg', 'Intravenous formulation available in a 100-mL glass vial containing 1000 mg (10 mg/mL)', '150 mg/kg in 5% dextrose or 1/2 NS given IV over 60 minutes (loading dose)', 'then 100 mg/kg in 5% dextrose or 1/2 NS over 16 hours', 'NAC solution concentrations of 40 mg/mL have been used to avoid fluid overload and hyponatremia in the neonate', 'Acetaminophen 10 mg/mL', 'Cimetidine 12 mg/mL', 'dexamethasone 10 mg/mL', 'diphenhydramine 50 mg/mL', 'dolasetron 20 mg/mL', 'fentanyl 50 mcg/mL', 'granisetron 0.1 mg/mL', 'heparin 100 units/mL', 'hydrocortisone 50 mg/mL', 'hydromorphone 4 mg/mL', 'ketorolac 15 mg/mL', 'lidocaine 20 mg/mL', 'lorazepam 0.5 mg/mL', 'mannitol 150 mg/mL (15%)', 'methylprednisolone 125 mg/mL', 'metoclopramide 5 mg/mL', 'midazolam 5 mg/mL', 'morphine 15 mg/mL', 'nalbuphine 20 mg/mL', 'ondansetron 2 mg/mL', 'potassium chloride 0.1 mEq/mL', '10 mg/kg/dose IV every 6 hours as needed or around-the-clock', 'Available orally in various liquid formulations containing 32, 80, and 100 mg/mL', 'Suppositories contain 80,120, 325, and 650 mg', 'Intravenous formulation available in a 100-mL glass vial containing 1000 mg (10 mg/mL)', '150 mg/kg in 5% dextrose or 1/2 NS given IV over 60 minutes (loading dose), followed by 50 mg/kg in 5% dextrose or 1/2 NS over 4 hours, then 100 mg/kg in 5% dextrose or 1/2 NS over 16 hours', 'NAC solution concentrations of 40 mg/mL have been used to avoid fluid overload and hyponatremia in the neonate', '0.01 to 0.05 mg/kg/dose orally every 8 to 12 hours', 'Available in 12.5-mg, 25-mg, 50-mg, and 100-mg tablets', 'Captopril oral suspension can be made by dissolving 6.25 mg (one-half of a scored 12.5-mg tablet) in 10 mL of sterile water, adding 1000 mg of sodium ascorbate for injection (4 mL of 250-mg/mL solution) to decrease oxidation, then adding sufficient water to make a final volume of 200 mL', 'The final concentration is 0.03 mg/mL captopril and 5 mg/mL sodium ascorbate', 'Dissolve one 200-mg tablet in 2.5-mL of water for a concentration of 80 mg/mL for oral or nasogastric (NG) tube administration', 'Doses used in these cases ranged from 70 to 200 mg/kg/day, administered as a single dose or over a 48-hour period', 'Available as a 200-mg tablet', 'Initial, 100 to 250 mg/kg/day divided into 2 to 4 doses per day concomitantly with other ammonia lowering agents', 'Based on retrospective case series (n=22), maintenance doses were typically less than 100 mg/kg/day', 'Dissolve one 200-mg tablet in 2.5-mL of water for a concentration of 80 mg/mL for oral or nasogastric (NG) tube administration', 'Doses used in these cases ranged from 70 to 200 mg/kg/day', '25 mg/m2 (or approximately 2 mg/kg) per dose every 24 hours', 'Administer by slow IV infusion over approximately 1 hour at a concentration not to exceed 0.5 mg/mL', 'Cancidas is supplied as a white to off-white powder cake in single-use vials, containing either 50 or 70 mg', 'To prepare the 50-mg (5 mg/mL) or 70-mg (7 mg/mL) CancidasÂ® vial', 'to a final concentration not to exceed 0.5 mg/mL', 'Maximum 330 mg/mL', 'Available as powder for injection in 500-mg and 1000-mg vials', 'Reconstitute 500-mg vial using 2 mL of sterile water for injection to a concentration of 225 mg/mL', 'Reconstitute 1000-mg vial using 3 mL of sterile water for injection to a concentration of 330 mg/mL', 'further dilute reconstituted drug to a concentration of 5 to 20 mg/mL in compatible solution', 'inject slowly over 3 to 5 minutes at a concentration of 100 mg/mL', 'For IM injection, use a concentration of 225 mg/mL', 'Maximum 330 mg/mL', 'Available as powder for injection in 500-mg and 1000-mg vials', 'Reconstitute 500-mg vial using 2 mL of sterile water for injection to a concentration of 225 mg/mL', 'Reconstitute 1000-mg vial using 3 mL of sterile water for injection to a concentration of 330 mg/mL', 'Available as powder for injection in 1-g and 2-g vials', 'Reconstitute 1-g vial with 9.5 mL sterile water for injection to a concentration of 100 mg/mL', '90 to 100 mg/kg/day IV divided every 8 hours', 'Give as an intermittent IV infusion at a concentration of 10 to 40 mg/mL over 15 to 60 minutes', 'Available as powder for injection in 500-mg and 1-g, 2-g, and 6-g vials', 'Reconstitute 500-mg vial with 10 mL of sterile water for injection to make a concentration of 50 mg/mL', 'Prepared by reconstituting 500-mg vial with 2.2 mL of 1% lidocaine without epinephrine or Sterile Water to a concentration of 200 mg/mL', '25 to 50 mg/kg (maximum 125 mg) IV/IM as a single dose', 'In all cases,the ceftriaxone dose (150 to 200 mg/kg/day) significantly exceeded the FDA recommended dose and/or was administered IV push', 'Available as a powder for injection in 250-mg, 500-mg, 1-g, and 2-g vials', 'Prepared by reconstituting powder with compatible solution (sterile water for injection, D5W, or D10W) to a concentration of 100 mg/mL', 'To make 40-mg/mL solution add 6.2 mL to the 250-mg vial', 'Prepared by reconstituting 250-mg vial with 0.9 mL of 1% lidocaine without epinephrine to a concentration of 250 mg/mL', '20 mg/kg IV every 8 hours', 'When reconstituted with NS to a final concentration between 2.5 to 50 mg/mL', 'Solutions prepared in D5W at concentrations of 1 to 20 mg/mL are stable in plastic syringes for up to 6 hours when refrigerated', 'Inject a 0.5-mg/mL solution of phentolamine subcutaneously into the affected area', 'Increase as needed to maximum of 3.5 mg/kg per dose every 6 hours', '0.25 mg/kg per dose every 6 hours', '0.01 mg/kg every 6 hours over 10 minutes', 'Increase as needed to maximum of 0.15 mg/kg per dose every 6 hours', 'Usual maintenance doses have been 2 to 3 mg/kg/day orally in 3 divided doses', 'Initial doses of 2 mg/kg/day orally in 3 divided doses have been used while some authors recommend starting at 0.3 to 1 mg/kg/day to assess tolerability and then increasing to 2 mg/kg/day incrementally over several days', 'Preterm infants less than 32 weeks Postmenstrual Age', 'Preterm infants greater than or equal to 32 weeks Postmenstrual Age', 'Administer IV over 15 minutes', 'dose should be administered within 6 hours', 'The administered volume in a neonate should always be 7.5 mL or less', 'Use with caution in patients with hepatocellular insufficiency, severe renal insufficiency, glucose 6 phosphate dehydrogenase deficiency, chronic malnutrition, or dehydration/hypovolemia', 'however, in a meta-analysis, the odds ratio (OR) was 1.6 (95% CI, 1.48 to 1.74)', 'Elimination half-life is approximately 3 hours in term neonates, 5 hours in preterm neonates greater than 32 weeks gestation, and up to 11 hours in more immature neonates', 'Elimination half-life is approximately 3 hours in term neonates', 'Injection site events (pain and site reactions; 15%) and vomiting (5%) occur with IV acetaminophen', 'Hypothermia did not develop in 99 neonates (93 normothermic and 6 with fever) administered IV acetaminophen', 'Hepatotoxicity occurred in less than 0.01% of children administered therapeutic doses of acetaminophen, in a systemic review (n=32,424; studies=62)', 'The estimated risk for minor or major hepatic events was 0.031% (95% CI, 0.015% to 0.057%)', 'and every 12 hours for less than 31 weeks postmenstrual age) in 189 infants (1 day to 182 days of age; 30 to 55 weeks PMA), in a retrospective analysis', 'Preterm infants 32 weeks postmenstrual age or older', 'Administer IV over 15 minutes', 'Withdraw appropriate dose and administer in bottle, bag, or IV syringe; dose should be administered within 6 hours', 'The administered volume in a neonate should always be 7.5 mL or less', 'glucose 6 phosphate dehydrogenase deficiency', 'however, in a meta-analysis, the odds ratio (OR) was 1.6 (95% CI, 1.48 to 1.74) for the risk of asthma in children', 'In 2 observational studies, the OR was 3.61 (95% CI, 1.33 to 9.77) for atopy and acetaminophen exposure before the age of 15 months', 'up to 2.39 (95% CI, 2.24 to 2.55) for rhinoconjunctivitis symptoms or 1.99 (95% CI, 1.82 to 2.16) for eczema symptoms and acetaminophen exposure in the previous 12 months in adolescents', 'Elimination half-life is approximately 3 hours in term neonates', '5 hours in preterm neonates greater than 32 weeks gestation', 'n=30, 1 to 90 days old, 31 to 40 weeks gestational age', 'Injection site events (pain and site reactions; 15%) and vomiting (5%) occur with IV acetaminophen', 'Hypothermia did not develop in 99 neonates (93 normothermic and 6 with fever) administered IV acetaminophen', 'Although data are limited for neonates, in children liver toxicity occurs with excessive doses or after prolonged administration (greater than 48 hours) of therapeutic', 'Hepatotoxicity occurred in less than 0.01% of children administered therapeutic doses of acetaminophen, in a systemic review (n=32,424; studies=62)', 'The estimated risk for minor or major hepatic events was 0.031% (95% CI, 0.015% to 0.057%)', 'No significant increases in liver enzymes were observed after a median duration of 60 hours (6 to 480 hours) and a median of 9 (2 to 80) doses of IV acetaminophen (20 mg/kg loading dose)', '30 to 55 weeks PMA', 'every 8 hours for 31 to 36 weeks PMA', 'every 6 hours for more than 36 weeks postmenstrual age (PMA)', 'and every 12 hours for less than 31 weeks postmenstrual age) in 189 infants (1 day to 182 days of age; 30 to 55 weeks PMA)', 'Acute liver failure occurred in an 11-month-old boy who received therapeutic doses of oral acetaminophen for a prolonged duration (10 days)', 'Treat localized herpes simplex disease for 14 days and disseminated or CNS disease for 21 days', 'Continue IV therapy for another 7 days', 'when repeat polymerase chain reaction (cerebrospinal fluid herpes simplex virus) is positive after approximately 21 days of acyclovir therapy', '(n=45 with CNS disease; n=29 with skin, eye, mouth (SEM) disease)', 'Of the 28 infants with CNS disease assessed at 12 months (acyclovir=16; placebo=12)', 'Bayley Scales of Infant Development (2nd Edition) Mental Scores were significantly higher in patients receiving acyclovir compared with patients receiving placebo (88.24 vs 68.12;p=0.046)', 'In patients with SEM disease receiving 6 months of suppressive oral acyclovir therapy started immediately after IV treatment, the time to 2 recurrences of skin lesions was 1.7 months longer in the treatment group compared with placebo', 'Of the 15 infants with SEM disease assessed at 12 months', 'An absolute neutrophil count of 500 cells/mm3 or less was reported in 20% to 25% of patients receiving acyclovir compared with 5% to 7% receiving placebo; no patient had complications associated with neutropenia', 'Dilution should be used within 24 hours', 'Treat localized herpes simplex disease for 14 days and disseminated or CNS disease for 21 days', 'infuse over 1 hour', 'The duration for preemptive therapy without proven disease is 10 days', 'Continue IV therapy for another 7 days', 'Neutropenia occurs in approximately 20% of patients', 'decrease dose or treat with GCSF if ANC remains less than 500/mm3', 'Phlebitis may occur at IV site due to alkaline pH of 10', 'D10W and sodium phenylacetate/sodium benzoate 10%', 'minor bleeding was more common in the warfarin group (33% vs 14%)', 'In a prospective, multicenter, randomized study (n=111) of warfarin vs aspirin for primary thromboprophylaxis in children after Fontan surgery', 'Clopidogrel should be discontinued 5 days prior to elective surgery if an antiplatelet effect is not desired', 'In one pediatric clinical study (n=17)', 'significant intracranial hemorrhage was reported in 25% of pediatric patients (n=2/9) when clopidogrel was used concomitantly with aspirin', '3% to 45% vs 53%, interquartile range, 38% to 65%; p=0.04)', 'Measure bleeding time prior to therapy initiation and 3 to 7 days after therapy initiation to assess drug efficacy', 'Monitor hematological parameters closely during the Micormedex NeoFax Essentials 2014 213 first few months of therapy and every 2 to 3 months in patients on long-term therapy', 'Suspension is stable for 60 days at room temperature or refrigerated.Shake well before use', 'Apply pressure to the lacrimal sac during and for 2 minutes after instillation to minimize systemic absorption', 'Maximal mydriasis occurs 30 to 60 minutes following administration', 'Recovery of accommodation occurs in 6 to 24 hours', 'Without lacrimal sac occlusion, approximately 80% of each drop may pass through the nasolacrimal system and be available for rapid systemic absorption by the nasal mucosa', 'Feedings should be withheld for 4 hours following procedure', 'Supplied as ophthalmic solution 0.5% in 15-mL Drop-tainers, and 1% and 2% concentrations in 2-, 5- and 15-mL Drop-tainers', 'A preparation containing cyclopentolate 0.2% and phenylephrine 1% is commercially available in 2- and 5-mL Drop-tainers', 'The final solution contains cyclopentolate 0.5%, tropicamide 0.5%,and phenylephrine 2.5%', 'Onset of action is 1 to 2 minutes after IV administration, with peak effect in 10 minutes', 'Dobutamine is most stable in solutions with a pH at or below 5', 'All fat emulsions have pH ranges from 6 to 9', 'Onset of action is 1 to 2 minutes after IV administration, with peak effect in 10 minutes', 'Dobutamine is most stable in solutions with a pH at or below 5', 'Serum half-life is 2 to 5 minutes', 'All fat emulsions have pH ranges from 6 to 9', 'Diluted solutions stable for 24 hours', '0.5 mL IM', 'Contains 6.7 Lf (flocculation units) of diphtheria toxoid and 5 Lf of tetanus toxoid', 'Fever (less than 39 degrees C; less than 102.2 degrees F) and/or small local reactions are common (35% to 55%)', 'DT vaccine (for pediatric use) is available as 0.5-mL single-dose vials', '0.5 mL IM in the anterolateral thigh', 'Five-dose series is started at 2 months of age (minimum age, 6 weeks)', 'in children who develop encephalopathy within 7 days following any DTP vaccination', 'Convulsions with or without fever occurring within 3 days', 'Hypotonic-hyporesponsive collapse or shock-like state within 48 hours', 'Temperature 40.5 degrees C (105 degrees F) or greater within 48 hours with no other cause', 'Store refrigerated at 2 to 8 degrees C (36 to 46 degrees F)', 'in children who develop encephalopathy within 7 days following any DTP vaccination', 'Temperature 40.5 degrees C (105 degrees F) or greater within 48 hours with no other cause', 'Store refrigerated at 2 to 8 degrees C (36 to 46 degrees F)', 'should not be administered to any infant before the age of 6 weeks', 'Types 1, 2, and 3 as IPV from a different manufacturer (Sanofi Pasteur)', 'Safety and efficacy of linezolid therapy for greater than 28 days has not been evaluated in controlled clinical trials', 'Serum half-life in most neonates is 2 to 3 hours', 'Lactic acidosis has been reported in a case series of 3 children aged 6 months, 6 months, and 16 years receiving linezolid for 53, 31 and 7 days of treatment']\n",
      "[' 1', '1', '1', '1', '1', ' 1', '1', '1', '1', '1', ' 1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0', '0']\n"
     ]
    }
   ],
   "source": [
    "def readfile(file):\n",
    " fp = codecs.open(file,\"rU\", encoding=\"utf8\",errors='ignore')\n",
    " text = fp.read()\n",
    " return text\n",
    "\n",
    "trainpath=\"D:\\\\model\\\\Training data\\\\total.txt\"                                                        \n",
    "traindata=readfile(trainpath)\n",
    "dataX=[]\n",
    "dataY=[]\n",
    "news=traindata.split(\"\\n\")\n",
    "for line in news:\n",
    "    line=line.strip()\n",
    "    feature,label=line.split(\":\",2)\n",
    "    dataX.append(feature)\n",
    "    dataY.append(label)\n",
    "\n",
    "\n",
    "print(dataX)\n",
    "print(dataY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(155, 605)\n",
      "(155,)\n",
      "(39, 605)\n",
      "(39,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(dataX).toarray()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer()\n",
    "datay=np.asarray(dataY)\n",
    "#print(datax)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, datay, test_size=0.2, random_state=0)\n",
    "#X_train1=X_train.reshape(3366,1)\n",
    "#y_train=y_train.reshape(3366,1)\n",
    "\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6387096774193548\n",
      "['1' '0' '0' '1' '0' '0' '1' '1' '1' '0' '0' '1' '1' '0' '1' '1' '1' '0'\n",
      " '1' '0' '1' '1' '0' '1' '1' '1' '0' '0' '0' '0' '0' '1' '0' '1' '1' '0'\n",
      " '0' '1' '0' '0' '1' '1' '1' '0' '0' '1' ' 1' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '1' ' 1' '1' '0' '1' '1' '0' '1' '1' '1' '1' '1' '1' '0' '1' '0'\n",
      " '0' '1' '1' '1' '0' '1' '0' '1' '1' '0' '0' '0' '1' '1' '1' '1' '0' '0'\n",
      " '0' '0' '0' '1' '0' '1' '0' '0' '1' '1' '1' '1' '0' '0' '1' '0' '0' '0'\n",
      " '1' '1' '0' '1' '0' '0' '1' '1' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0'\n",
      " '1' '0' '1' '1' '0' '0' '0' '1' '1' '1' '0' '1' '0' '0' '0' '1' '1' '0'\n",
      " '1' '1' '1' '1' '1' '1' '0' '1' '0' '1' '0']\n",
      "['1' '0' '0' '1' '0' '0' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '1' '0' '0' '0' '1' '1' '0' '0' '0' '1' '1' '1' '0' '0' '0' '0'\n",
      " '0' '0' '1' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '1' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '1' '0' '1' '0' '0' '0' '0' '1' '0' '1' '0']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "km = KMeans(n_clusters=2)\n",
    "km.fit(X_train)\n",
    "train=km.predict(X_train)\n",
    "train=train.astype(str)\n",
    "labels = km.labels_\n",
    "print('accuracy %s' % accuracy_score(train, y_train))\n",
    "print(y_train)\n",
    "print(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "ypred = km.predict(X_test)\n",
    "ypred=ypred.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6410256410256411\n",
      "['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0'\n",
      " '0' '0' '0']\n",
      "['0' '0' '1' '1' '1' '1' '1' '0' '0' '1' ' 1' '0' '0' '0' '1' '1' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '0' '1' '0' '1' '1' '0'\n",
      " '1' '0' '1']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print('accuracy %s' % accuracy_score(ypred, y_test))\n",
    "\n",
    "print(ypred)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.38461538461538464\n"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "#HMM Model\n",
    "gm = hmm.GaussianHMM(n_components=2)\n",
    "gm.fit(X_train)\n",
    "states = gm.predict(X_train)\n",
    "\n",
    "ypred=gm.predict(X_test)\n",
    "\n",
    "ypred=ypred.astype(str)\n",
    "\n",
    "print('accuracy %s' % accuracy_score(ypred, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"\\nK Nearest Neighbors:\")\\nfor rank, index in enumerate(indices[0][:2], start = 1):\\n   print(str(rank) + \" is\", X[index])\\n'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=2) \n",
    "  \n",
    "knn_model = NearestNeighbors(n_neighbors = 2, algorithm = 'auto').fit(X_train)\n",
    "distances, indices = knn_model.kneighbors(X_test)\n",
    "\n",
    "#print(distances) \n",
    "#print(indices)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "print(\"\\nK Nearest Neighbors:\")\n",
    "for rank, index in enumerate(indices[0][:2], start = 1):\n",
    "   print(str(rank) + \" is\", X[index])\n",
    "\"\"\"\n",
    "#print('accuracy %s' % accuracy_score(indices, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(file):\n",
    " fp = codecs.open(file,\"rU\", encoding=\"utf8\",errors='ignore')\n",
    " text = fp.read()\n",
    " return text\n",
    "\n",
    "import codecs\n",
    "\n",
    "trainpath1=\"D:\\\\model\\\\Training data\\\\hasDuration.txt\"                                                        \n",
    "traindata1=readfile(trainpath1)\n",
    "dataX1=[]\n",
    "dataY1=[]\n",
    "news1=traindata1.split(\"\\n\")\n",
    "for line in news1:\n",
    "    line=line.strip()\n",
    "    feature1,label1=line.split(\":\",2)\n",
    "    dataX1.append(feature1)\n",
    "    dataY1.append(label1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X1 = vectorizer.fit_transform(dataX1).toarray()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer()\n",
    "datay1=np.asarray(dataY1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "km1 = KMeans(n_clusters=2)\n",
    "km1.fit(X1)\n",
    "train1=km1.predict(X1)\n",
    "train1=train1.astype(str)\n",
    "labels = km1.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5210084033613446\n",
      "[' 1' '1' '0' '0' '1' '0' '1' ' 1' '0' '1' '1' '1' '0' ' 1' '1' '1' '0'\n",
      " '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0'\n",
      " '1' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '1' '1' '0' '0' '1' '1' '1' '1' '0' '0' '0' '1' '1'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '1'\n",
      " '0' '0' '0' '1' '1' '1' '1' '1' '1' '0' '0' '0' '1' '1' '1' '1' '1' '0'\n",
      " '0' '0' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '0' '1' '1' '0'\n",
      " '1' '1' '1' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1'\n",
      " '1' '1' '1' '1' '0' '1' '0' '0' '0' '1' '0' '1' '1' '1' '1' '1' '1' '1'\n",
      " '0' '0' '1' '0' '1' '0' '1' '0' '0' '0' '0' '0' '1' '1' '1' '1' '1' '0'\n",
      " '1' '1' '0' '1' '0' '1' '0' '0' '1' '0' '0' '1' '0' '0' '1' '1' '1' '1'\n",
      " '1' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0' '0' '1' '0' '0' '0' '1' '1'\n",
      " '1' '1' '1' '1' '1']\n",
      "['1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '0' '0' '0' '1' '1'\n",
      " '0' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '0'\n",
      " '0' '1' '0' '0' '0' '0' '1' '1' '1' '1' '0' '1' '1' '1' '1' '0' '1' '1'\n",
      " '1' '0' '0' '0' '0' '1' '1' '1' '0' '0' '1' '0' '1' '0' '1' '0' '0' '1'\n",
      " '1' '1' '0' '0' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '0'\n",
      " '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '0' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '0' '0' '1' '1' '0' '1' '1' '1' '1' '1' '1' '0' '0' '0' '1' '1' '1'\n",
      " '1' '1' '1' '1']\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(train1, datay1))\n",
    "print(datay1)\n",
    "print(train1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(file):\n",
    " fp = codecs.open(file,\"rU\", encoding=\"utf8\",errors='ignore')\n",
    " text = fp.read()\n",
    " return text\n",
    "\n",
    "import codecs\n",
    "\n",
    "trainpath2=\"D:\\\\model\\\\Training data\\\\hasVolume.txt\"                                                        \n",
    "traindata2=readfile(trainpath2)\n",
    "dataX2=[]\n",
    "dataY2=[]\n",
    "news2=traindata2.split(\"\\n\")\n",
    "for line1 in news2:\n",
    "    line1=line1.strip()\n",
    "    feature2,label2=line1.split(\":\",2)\n",
    "    dataX2.append(feature2)\n",
    "    dataY2.append(label2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X2 = vectorizer.fit_transform(dataX2).toarray()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer()\n",
    "datay2=np.asarray(dataY2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "km2 = KMeans(n_clusters=2)\n",
    "km2.fit(X2)\n",
    "train2=km2.predict(X2)\n",
    "train2=train2.astype(str)\n",
    "labels2 = km2.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.18505338078291814\n",
      "['1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '0' '0' '1' '0' '0' '1' '1' '1'\n",
      " '0' '1' '1' '1' '1' '0' '1' '0' '0' '1' '0' '1' '0' '0' '0' '0' '1' '0'\n",
      " '1' '0' '1' '0' '1' '0' '0' '1' '1' '0' '1' '0' '1' '1' '0' '1' '0' '1'\n",
      " '1' '1' '1' '1' '0' '0' '1' '1' '1' '0' '0' '1' '1' '1' '1' '1' '1' '0'\n",
      " '0' '0' '0' '1' '1' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1'\n",
      " '0' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '0' '0'\n",
      " '1' '1' '1' '1' '0' '0' '1' '0' '1' '1' '1' '0' '0' '1' '1' '1' '0' '0'\n",
      " '0' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1']\n",
      "['1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '0' '0' '1' '0' '0' '1' '1' '1'\n",
      " '0' '1' '1' '1' '1' '0' '1' '0' '0' '1' '0' '1' '0' '0' '0' '0' '1' '0'\n",
      " '1' '0' '1' '0' '1' '0' '0' '1' '1' '0' '1' '0' '1' '1' '0' '1' '0' '1'\n",
      " '1' '1' '1' '1' '0' '0' '1' '1' '1' '0' '0' '1' '1' '1' '1' '1' '1' '0'\n",
      " '0' '0' '0' '1' '1' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1'\n",
      " '0' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '0' '0'\n",
      " '1' '1' '1' '1' '0' '0' '1' '0' '1' '1' '1' '0' '0' '1' '1' '1' '0' '0'\n",
      " '0' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1']\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(train2, dataY2))\n",
    "print(train2)\n",
    "print(train2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readfile(file):\n",
    " fp = codecs.open(file,\"rU\", encoding=\"utf8\",errors='ignore')\n",
    " text = fp.read()\n",
    " return text\n",
    "\n",
    "import codecs\n",
    "\n",
    "trainpath4=\"D:\\\\model\\\\Training data\\\\hasConcentration.txt\"                                                        \n",
    "traindata4=readfile(trainpath4)\n",
    "dataX4=[]\n",
    "dataY4=[]\n",
    "news4=traindata4.split(\"\\n\")\n",
    "for line4 in news4:\n",
    "    line4=line4.strip()\n",
    "    feature4,label4=line4.split(\":\",2)\n",
    "    dataX4.append(feature4)\n",
    "    dataY4.append(label4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X4 = vectorizer.fit_transform(dataX4).toarray()\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidfconverter = TfidfVectorizer()\n",
    "datay4=np.asarray(dataY4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X4, datay4, test_size=0.8, random_state=0)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "km4 = KMeans(n_clusters=2)\n",
    "km4.fit(X_train)\n",
    "train4=km4.predict(X_train)\n",
    "train4=train4.astype(str)\n",
    "labels4 = km4.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6451612903225806\n",
      "['1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '0' '0' '1' '0' '0' '1' '1' '1'\n",
      " '0' '1' '1' '1' '1' '0' '1' '0' '0' '1' '0' '1' '0' '0' '0' '0' '1' '0'\n",
      " '1' '0' '1' '0' '1' '0' '0' '1' '1' '0' '1' '0' '1' '1' '0' '1' '0' '1'\n",
      " '1' '1' '1' '1' '0' '0' '1' '1' '1' '0' '0' '1' '1' '1' '1' '1' '1' '0'\n",
      " '0' '0' '0' '1' '1' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '1'\n",
      " '0' '1' '1' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '0' '0' '0'\n",
      " '1' '1' '1' '1' '0' '0' '1' '0' '1' '1' '1' '0' '0' '1' '1' '1' '0' '0'\n",
      " '0' '1' '1' '0' '1' '1' '1' '1' '1' '1' '1']\n",
      "['0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '0' '0'\n",
      " '1' '1' '0' '0' '0' '1' '1' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '0' '0' '0' '0' '0'\n",
      " '1' '0' '0' '0' '0' '1' '0' '1' '0' '0' '0' '0' '1' '1' '1' '1' '0' '1'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '1' '0' '1' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '1' '0' '1' '0' '0' '1' '1' '0' '0' '0' '0' '0' '0' ' 0' '0' '0' '0' '1'\n",
      " ' 1' '0' '0' '1' '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' ' 0' '0' '0' '0' '0' ' 0' '0' '0' '0' '1' ' 1' '0' '0' '0'\n",
      " '0' '0' '0' '0' '1' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '0' '0' '0' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '0' '0' '0' '0' '0' '1' '0' '0' '0' '1' '1' '0' '0' '0' '0' '1' '0' '0'\n",
      " '1' '0' '0' '1' '0' '0' '0' '1' '1' '1' '1' '1' '0' '0' '1' '1' '0' '1'\n",
      " '0' '1' '0' '1' '1' '0' '0' '0' '1' '0' '1' '0' '1' '0' '0' '0' '0' '0'\n",
      " '0' '0' '0' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1' '1'\n",
      " '1' '1' '1' '1' '1' '1' '1' '1']\n",
      "accuracy 0.16334661354581673\n"
     ]
    }
   ],
   "source": [
    "print('accuracy %s' % accuracy_score(train4, y_train))\n",
    "print(train2)\n",
    "print(datay4)\n",
    "km4.fit(X_test)\n",
    "test4=km4.predict(X_test)\n",
    "test4=test4.astype(str)\n",
    "print('accuracy %s' % accuracy_score(test4, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Time (s): 0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monika\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\Users\\monika\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py:225: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  for func, args, kwargs in self.items]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pomegranate import NaiveBayes, NormalDistribution\n",
    "model = NaiveBayes.from_samples(NormalDistribution, X4, datay4, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
